{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, precision_score, recall_score, roc_auc_score\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "-RYnGZBFXiWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notes=pd.read_csv('Final_SWmerged.csv')"
      ],
      "metadata": {
        "id": "ngl_3ektXj-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-processing**"
      ],
      "metadata": {
        "id": "K2mskXwhFOXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notes[\"TEXT\"] = [note.lower() for note in notes[\"TEXT\"]]"
      ],
      "metadata": {
        "id": "DdIjXGbWqF8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(df):\n",
        "  text = str(df[\"TEXT\"])\n",
        "  clean = re.sub(r\"\\n\",\"\",text)\n",
        "  cleaner = re.sub(r\"  \",\"\",clean)\n",
        "\n",
        "  return cleaner"
      ],
      "metadata": {
        "id": "ItSsjETpok4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notes[\"TEXT_CLEAN\"] = notes.apply(clean_text, axis=1)"
      ],
      "metadata": {
        "id": "AFBDA7wgq7eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = notes.iloc[:,11:15]"
      ],
      "metadata": {
        "id": "tA6nhIkXud7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifier"
      ],
      "metadata": {
        "id": "YZ-nf5qdFdVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Vectorize text\n",
        "countvec_bow = CountVectorizer(ngram_range = (1,3), stop_words='english')\n",
        "list_notes = list(notes[\"TEXT_CLEAN\"])\n",
        "notes_bow = countvec_bow.fit_transform(list_notes)"
      ],
      "metadata": {
        "id": "qbxw5PwL7Xib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert x and y to np arrays\n",
        "label_array = np.array(labels)"
      ],
      "metadata": {
        "id": "iqIruqYA-Rvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LR_trainer(X_trn,y_trn,l):\n",
        "\n",
        "  p_avgs = []\n",
        "  r_avgs = []\n",
        "  f1_avgs = []\n",
        "\n",
        "  p_idvs = []\n",
        "  r_idvs = []\n",
        "  f1_idvs = []\n",
        "\n",
        "  lr = LogisticRegression(penalty='none',C=1/l) #solver='saga',l1_ratio=0.5\n",
        "  mt_lr = MultiOutputClassifier(lr, n_jobs=1)\n",
        "\n",
        "  kf = KFold(n_splits=5, shuffle=True,random_state= 1)\n",
        "\n",
        "  for train_index, test_index in kf.split(X_trn):\n",
        "    X_train, X_test = X_trn[train_index], X_trn[test_index]\n",
        "    y_train, y_test = y_trn[train_index], y_trn[test_index]\n",
        "\n",
        "    fit_model = mt_lr.fit(X_train,y_train)\n",
        "    y_pred = fit_model.predict(X_test)\n",
        "\n",
        "    #Precision, recall, f-score\n",
        "\n",
        "    p_avg = precision_score(y_test, y_pred, average='macro')\n",
        "    r_avg = recall_score(y_test, y_pred, average='macro')\n",
        "    f_avg = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "    p_idv = precision_score(y_test, y_pred, average=None)\n",
        "    r_idv = recall_score(y_test, y_pred, average=None)\n",
        "    f_idv = f1_score(y_test, y_pred, average=None)\n",
        "\n",
        "    p_avgs.append(p_avg)\n",
        "    r_avgs.append(r_avg)\n",
        "    f1_avgs.append(f_avg)\n",
        "\n",
        "    p_idvs.append(p_idv)\n",
        "    r_idvs.append(r_idv)\n",
        "    f1_idvs.append(f_idv)\n",
        "\n",
        "  p_avg_cv = sum(p_avgs)/5\n",
        "  r_avg_cv = sum(r_avgs)/5\n",
        "  f1_avg_cv = sum(f1_avgs)/5\n",
        "\n",
        "  p_std = np.std(p_avgs)\n",
        "  r_std = np.std(r_avgs)\n",
        "  f1_std = np.std(f1_avgs)\n",
        "\n",
        "  p_idv_cv = sum(p_idvs)/5\n",
        "  r_idv_cv = sum(r_idvs)/5\n",
        "  f1_idv_cv = sum(f1_idvs)/5\n",
        "\n",
        "  p_idv_std = np.std(p_idvs,axis=0)\n",
        "  r_idv_std = np.std(r_idvs,axis=0)\n",
        "  f1_idv_std = np.std(f1_idvs,axis=0)\n",
        "\n",
        "  #Calculating CIs\n",
        "\n",
        "  p_ci = []\n",
        "  r_ci = []\n",
        "  f1_ci = []\n",
        "\n",
        "  p_ci_lb = p_avg_cv - (1.96*p_std)\n",
        "  p_ci_ub = p_avg_cv + (1.96*p_std)\n",
        "  p_ci.append(p_ci_lb)\n",
        "  p_ci.append(p_ci_ub)\n",
        "\n",
        "  r_ci_lb = r_avg_cv - (1.96*r_std)\n",
        "  r_ci_ub = r_avg_cv + (1.96*r_std)\n",
        "  r_ci.append(r_ci_lb)\n",
        "  r_ci.append(r_ci_ub)\n",
        "\n",
        "  f1_ci_lb = f1_avg_cv - (1.96*f1_std)\n",
        "  f1_ci_ub = f1_avg_cv + (1.96*f1_std)\n",
        "  f1_ci.append(f1_ci_lb)\n",
        "  f1_ci.append(f1_ci_ub)\n",
        "\n",
        "  #CIs for each category\n",
        "\n",
        "  #Precision\n",
        "\n",
        "  p_ci_ES = []\n",
        "  p_ci_CF = []\n",
        "  p_ci_C = []\n",
        "  p_ci_PA = []\n",
        "\n",
        "  p_ES_lb = p_idv_cv[0] - (1.96*p_idv_std[0])\n",
        "  p_ES_ub = p_idv_cv[0] + (1.96*p_idv_std[0])\n",
        "  p_ci_ES.append(p_ES_lb)\n",
        "  p_ci_ES.append(p_ES_ub)\n",
        "\n",
        "  p_CF_lb = p_idv_cv[1] - (1.96*p_idv_std[1])\n",
        "  p_CF_ub = p_idv_cv[1] + (1.96*p_idv_std[1])\n",
        "  p_ci_CF.append(p_CF_lb)\n",
        "  p_ci_CF.append(p_CF_ub)\n",
        "\n",
        "  p_C_lb = p_idv_cv[2] - (1.96*p_idv_std[2])\n",
        "  p_C_ub = p_idv_cv[2] + (1.96*p_idv_std[2])\n",
        "  p_ci_C.append(p_C_lb)\n",
        "  p_ci_C.append(p_C_ub)\n",
        "\n",
        "  p_PA_lb = p_idv_cv[3] - (1.96*p_idv_std[3])\n",
        "  p_PA_ub = p_idv_cv[3] + (1.96*p_idv_std[3])\n",
        "  p_ci_PA.append(p_PA_lb)\n",
        "  p_ci_PA.append(p_PA_ub)\n",
        "\n",
        "  #Recall\n",
        "\n",
        "  r_ci_ES = []\n",
        "  r_ci_CF = []\n",
        "  r_ci_C = []\n",
        "  r_ci_PA = []\n",
        "\n",
        "  r_ES_lb = r_idv_cv[0] - (1.96*r_idv_std[0])\n",
        "  r_ES_ub = r_idv_cv[0] + (1.96*r_idv_std[0])\n",
        "  r_ci_ES.append(r_ES_lb)\n",
        "  r_ci_ES.append(r_ES_ub)\n",
        "\n",
        "  r_CF_lb = r_idv_cv[1] - (1.96*r_idv_std[1])\n",
        "  r_CF_ub = r_idv_cv[1] + (1.96*r_idv_std[1])\n",
        "  r_ci_CF.append(r_CF_lb)\n",
        "  r_ci_CF.append(r_CF_ub)\n",
        "\n",
        "  r_C_lb = r_idv_cv[2] - (1.96*r_idv_std[2])\n",
        "  r_C_ub = r_idv_cv[2] + (1.96*r_idv_std[2])\n",
        "  r_ci_C.append(r_C_lb)\n",
        "  r_ci_C.append(r_C_ub)\n",
        "\n",
        "  r_PA_lb = r_idv_cv[3] - (1.96*r_idv_std[3])\n",
        "  r_PA_ub = r_idv_cv[3] + (1.96*r_idv_std[3])\n",
        "  r_ci_PA.append(r_PA_lb)\n",
        "  r_ci_PA.append(r_PA_ub)\n",
        "\n",
        "  #F1\n",
        "\n",
        "  f1_ci_ES = []\n",
        "  f1_ci_CF = []\n",
        "  f1_ci_C = []\n",
        "  f1_ci_PA = []\n",
        "\n",
        "  f1_ES_lb = f1_idv_cv[0] - (1.96*f1_idv_std[0])\n",
        "  f1_ES_ub = f1_idv_cv[0] + (1.96*f1_idv_std[0])\n",
        "  f1_ci_ES.append(f1_ES_lb)\n",
        "  f1_ci_ES.append(f1_ES_ub)\n",
        "\n",
        "  f1_CF_lb = f1_idv_cv[1] - (1.96*f1_idv_std[1])\n",
        "  f1_CF_ub = f1_idv_cv[1] + (1.96*f1_idv_std[1])\n",
        "  f1_ci_CF.append(f1_CF_lb)\n",
        "  f1_ci_CF.append(f1_CF_ub)\n",
        "\n",
        "  f1_C_lb = f1_idv_cv[2] - (1.96*f1_idv_std[2])\n",
        "  f1_C_ub = f1_idv_cv[2] + (1.96*f1_idv_std[2])\n",
        "  f1_ci_C.append(f1_C_lb)\n",
        "  f1_ci_C.append(f1_C_ub)\n",
        "\n",
        "  f1_PA_lb = f1_idv_cv[3] - (1.96*f1_idv_std[3])\n",
        "  f1_PA_ub = f1_idv_cv[3] + (1.96*f1_idv_std[3])\n",
        "  f1_ci_PA.append(f1_PA_lb)\n",
        "  f1_ci_PA.append(f1_PA_ub)\n",
        "\n",
        "  return p_idv_cv,p_avg_cv,r_idv_cv,r_avg_cv,f1_idv_cv,f1_avg_cv,p_ci_ES,p_ci_CF,p_ci_C,p_ci_PA,p_ci,r_ci_ES,r_ci_CF,r_ci_C,r_ci_PA,r_ci,f1_ci_ES,f1_ci_CF,f1_ci_C,f1_ci_PA,f1_ci"
      ],
      "metadata": {
        "id": "4PQYDqJInezY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_trainer(notes_bow,label_array,0.001) #Results are with elastic net"
      ],
      "metadata": {
        "id": "hQcW-7V4OUNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR_trainer(notes_bow,label_array,1) #No regualrization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubyl-S-YLgrZ",
        "outputId": "91a0fb4b-da89-4102-8a6a-d520f628af8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.86872482, 0.63037836, 0.44694444, 0.77529221]),\n",
              " 0.6803349583321645,\n",
              " array([0.77238014, 0.43858748, 0.14373182, 0.43568554]),\n",
              " 0.4475962459186184,\n",
              " array([0.81687138, 0.51408271, 0.21468628, 0.55561112]),\n",
              " 0.5253128702968197,\n",
              " [0.7768105421823455, 0.960639095415154],\n",
              " [0.5535244480782523, 0.7072322765082596],\n",
              " [0.048597098650306425, 0.8452917902385826],\n",
              " [0.6481385786680296, 0.9024458369163859],\n",
              " [0.5694654751843837, 0.7912044414799453],\n",
              " [0.7421095060955312, 0.8026507759127359],\n",
              " [0.3102985121467259, 0.5668764418308837],\n",
              " [-0.01614988287354352, 0.3036135263081488],\n",
              " [0.3774175934525042, 0.49395349447596076],\n",
              " [0.37600145209870095, 0.5191910397385359],\n",
              " [0.7798611198362634, 0.8538816403180843],\n",
              " [0.42689473844746534, 0.6012706765558311],\n",
              " [-0.007545899910601506, 0.436918454474238],\n",
              " [0.5108462252611035, 0.6003760073921738],\n",
              " [0.45772726170751665, 0.5928984788861228])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}